{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Real Estate EDA"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Imports (Pandas - Python Data Analysis Library, Numbpy - Array Proessing Package, Seaborn - Statistical Data Visualisation, Matplotlib - Static Vizualization Library)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Standard Import Structure for EDA;\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import regex as re\n",
    "import random\n",
    "import csv\n",
    "\n",
    "# Importing Requests for use in API calls.\n",
    "import requests\n",
    "\n",
    "\n",
    "# Import Standard Packages for Date and Time;\n",
    "from datetime import datetime, timedelta\n",
    "\n",
    "# Import Beautiful Soup, Selenium, for Scraping\n",
    "from bs4 import BeautifulSoup\n",
    "from selenium import webdriver\n",
    "from selenium.webdriver.common.keys import Keys\n",
    "from selenium.webdriver.common.by import By\n",
    "\n",
    "# Import packages to help with parsing Information\n",
    "import lxml\n",
    "from lxml.html.soupparser import fromstring\n",
    "import prettify\n",
    "import numbers\n",
    "import htmltext\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Setup of User-Agent Randomization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1000\n"
     ]
    }
   ],
   "source": [
    "with open ('userAgents.txt', 'r') as f:\n",
    "    data = f.read()\n",
    "    userAgentList = data.split('\\n')\n",
    "    f.close()\n",
    "\n",
    "print(str(len(userAgentList)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def GET_UA():\n",
    "    return random.choice(userAgentList)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Setup Of Proxy Randomization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "300\n"
     ]
    }
   ],
   "source": [
    "with open ('proxies.txt','r') as f:\n",
    "    data = f.read()\n",
    "    proxyList = data.split('\\n')\n",
    "    f.close()\n",
    "print(str(len(proxyList)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def GET_PROX():\n",
    "    return random.choice(proxyList)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Setup and Initialization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "       Expensive     Affordable\n",
      "0       Cashiers     Greenville\n",
      "1      Highlands  Winston Salem\n",
      "2      Nags Head   Fayetteville\n",
      "3   Holden Beach     Kannapolis\n",
      "4   Emerald Isle     Greensboro\n",
      "5   Blowing Rock        Concord\n",
      "6     Banner Elk      Lexington\n",
      "7       Davidson    Thomasville\n",
      "8    Chapel Hill       Asheboro\n",
      "9         Durham    Rocky Mount\n",
      "10   Wake Forest        Sanford\n"
     ]
    }
   ],
   "source": [
    "# Set Maximum Displayed Columns to None; All Columns Listed\n",
    "pd.options.display.max_columns = None;\n",
    "\n",
    "# Set MatPlotLib to Display Elements\n",
    "%matplotlib inline\n",
    "\n",
    "# Import Cities in CSV file for 10 most and least expenive north carolina cities.csv\n",
    "cities_df = pd.read_csv(\"cities2.csv\",header=0)\n",
    "\n",
    "#Lists for Looping through GET Requests\n",
    "urls = list()\n",
    "cities = list()\n",
    "\n",
    "# Create Headers for Future GET Requests\n",
    "req_headers = {\"User-Agent\":GET_UA(),\n",
    "    \"Accept-Language\":\"en-US,en;q=0.9\",\n",
    "    \"Accept\":\"text/html,application/xhtml+xml,application/xml;q=0.9,image/avif,image/webp,image/apng,*/*;q=0.8,application/signed-exchange;v=b3;q=0.9\",\n",
    "    \"Accept-Encoding\":\"gzip, deflate, br\",\n",
    "    \"upgrade-insecure-requests\":\"1\"}\n",
    "\n",
    "# Print cities list to double check correct information\n",
    "print(cities_df)\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Create URLs For Scraping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "66\n"
     ]
    }
   ],
   "source": [
    "# Checking for Sale using Zillow.com\n",
    "# Using 20 Cities we use 20 URLs\n",
    "# Using loop to collect information from csv to pass to beautiful soup\n",
    "for i in range(11):\n",
    "    for j in range(2):\n",
    "        # Get City List from cities_df\n",
    "        cities.append(str(cities_df.iat[i,j]))\n",
    "\n",
    "# SUCCESSFUL CHECKING FOR INCLUSION OF ALL OF CITIES FILES REQUIRED\n",
    "# Uncomment for initial check and recomment for readability afterwards\n",
    "# print(cities)\n",
    "\n",
    "# Remove White Space to Make A Correct URL by Replacing with '_'\n",
    "# E.g. 'Morehead City' -> 'Morehead_City'\n",
    "for i in range(0,len(cities)):\n",
    "    city = str(cities[i]).replace(' ','_')\n",
    "    cities[i] = city\n",
    "\n",
    "\n",
    "# SUCCESSFUL CHECKING FOR CORRECT FORMAT (city with space === city_with_space) REQUIRED\n",
    "# Uncomment for initial check and recomment for readability afterwards\n",
    "# print(cities)\n",
    "\n",
    "\n",
    "# Creating the URLS based upon created cities list\n",
    "for i in range(0,len(cities)):\n",
    "    urls.append('https://www.zillow.com/homes/for_sale/'+cities[i]+',-NC_rb/')\n",
    "\n",
    "# Create Additional URLS based on further page exploration...\n",
    "# Placed Last so quick excel viewing gives snapshot of individual cities and in-depth numbers are furthur down.\n",
    "# ***** Can Rarely Handle 5 Pages From 20 Cities *****\n",
    "# # ***** Options Are Including More Cities and Less Pages, or Vice-Versa *****\n",
    "for i in range(2,4):\n",
    "    for j in range(0,len(cities)):\n",
    "        urls.append('https://www.zillow.com/homes/for_sale/'+cities[j]+',-NC_rb/'+str(i)+'_p/')\n",
    "\n",
    "# SUCCESSFUL CHECKING FOR APPROPRAITE URLs REQUIRED\n",
    "# Uncomment for initial check and recomment for readability afterwards\n",
    "print(len(urls))\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Create Session and Loop Trough URLs with GET Requests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Amount of listings Scraped: 108\n"
     ]
    }
   ],
   "source": [
    "# Object for Individual Listings to be placed into List\n",
    "# List to Store Total Scraped Information\n",
    "l=list()\n",
    "obj = {}\n",
    "# Setup Cost to be added to data frame using list\n",
    "cost = []\n",
    "# Setup Beds to be added to data frame using list\n",
    "beds = []\n",
    "# Setup Baths to be added to data frame using list\n",
    "baths = []\n",
    "# Setup Square Feet to be added to data frame using list\n",
    "sqft = []\n",
    "# Setup Types to be added to data frame using list\n",
    "types = []\n",
    "# Setup Address to be added to data frame using list\n",
    "address = []\n",
    "\n",
    "\n",
    "# Create a DataFrame for Storage with Columns listing Wanted Information\n",
    "house_df = pd.DataFrame(columns=['Price','Beds','Baths','Square_Feet','Type','Address'])\n",
    "\n",
    "#loop through sessions to get urls used be Reqeusts Package for pulling information\n",
    "\n",
    "for i in range(0,len(urls)):\n",
    "    proxy = GET_PROX()\n",
    "    try:\n",
    "        r = requests.get(urls[i], headers=req_headers, proxies={'http': f\"http://{proxy}\"})\n",
    "    except ProxyError:\n",
    "        r = requests.get(urls[i], headers=req_headers, proxies={'https': f\"https://{proxy}\"})\n",
    "    except:\n",
    "        r = requests.get(urls[i], headers=req_headers)\n",
    "\n",
    "    # Parse bs4 response into html parser\n",
    "    soup = BeautifulSoup(r.text, 'html.parser')\n",
    "    \n",
    "\n",
    "    # Loop through the created soup to add to df\n",
    "    for i in soup:\n",
    "        properties = soup.find_all(\"div\",{\"class\":\"StyledPropertyCardDataWrapper-c11n-8-73-8__sc-1omp4c3-0 gXNuqr property-card-data\"})\n",
    "        \n",
    "        for x in range(0,len(properties)):\n",
    "            \n",
    "            # Try and get pricing from listing excluding those without a number\n",
    "            try:\n",
    "                obj[\"pricing\"]=properties[x].find(\"div\",{\"class\":\"StyledPropertyCardDataArea-c11n-8-73-8__sc-yipmu-0 hRqIYX\"}).text\n",
    "            except:\n",
    "                obj[\"pricing\"]=None\n",
    "\n",
    "            # Try to get Information Sizing\n",
    "            # i.e. Beds, Baths, Square Feet, and Type (House, Apartment, Single-Family or Multi-Family Home)\n",
    "            try:\n",
    "                sizeInfo=properties[x].find(\"div\",{\"class\":\"StyledPropertyCardDataArea-c11n-8-73-8__sc-yipmu-0 ghGYOB\"}).text\n",
    "\n",
    "                # Format Correctly The Sizing Information for Split\n",
    "\n",
    "                # Steps:\n",
    "                # Remove Sq Ft Unit\n",
    "                # Remove Additional Info Indicator '-'\n",
    "                # Remove 'For Sale' Descriptor\n",
    "                # Remove WhiteSpace\n",
    "                # Correctly Gap Beds and Baths (Bd, and Ba) to be Uniform\n",
    "                # Remove Commas for Easier Delimitor for Later Split\n",
    "                sizeInfo = sizeInfo.replace('sqft','',1)\n",
    "                sizeInfo = sizeInfo.replace(' - ','')\n",
    "                sizeInfo = sizeInfo.replace(' for sale',\"\")\n",
    "\n",
    "                sizeInfo = sizeInfo.replace(\" \",\"\",2)\n",
    "\n",
    "                sizeInfo = sizeInfo.replace('bds','bd')\n",
    "                sizeInfo = sizeInfo.replace('bd','bd ')\n",
    "                sizeInfo = sizeInfo.replace('ba','ba ')\n",
    "                sizeInfo = sizeInfo.replace(',','')\n",
    "\n",
    "                # Create split based on whitespace and only 3 split times for grouping construction details\n",
    "                split = sizeInfo.split(' ',3)\n",
    "                \n",
    "                # Place information into object for later use\n",
    "                # Edit Some Info --- If Land It is Ending up in 'Beds', and Type is Ending up in Baths\n",
    "\n",
    "                if split[0].count('acre') or split[0].count('lot'):\n",
    "                    obj['sqft'] = split[0]\n",
    "                    obj['beds'] = 0\n",
    "                    obj['baths'] = 0\n",
    "                    obj['type'] = split[3]\n",
    "                else:\n",
    "                    obj['beds'] = split[0]\n",
    "                    obj['baths'] = split[1]\n",
    "                    obj['sqft'] = split[2]\n",
    "                    obj['type'] = split[3]\n",
    "                \n",
    "            except:\n",
    "                sizeInfo=None\n",
    "\n",
    "            # Find Address information and exclude those without written address\n",
    "            try:\n",
    "                obj[\"address\"]=properties[x].find(\"a\",{\"class\":\"StyledPropertyCardDataArea-c11n-8-73-8__sc-yipmu-0 lhIXlm property-card-link\"}).text\n",
    "            except:\n",
    "                obj[\"address\"]=None\n",
    "                \n",
    "            l.append(obj)  \n",
    "            obj={}\n",
    "\n",
    "\n",
    "\n",
    "# If you really want to check for log output\n",
    "\n",
    "# For Whole Log\n",
    "# print(l)\n",
    "\n",
    "# For Segment Wanted\n",
    "# for i in range(0,len(l)):\n",
    "#   print(l[i]['sqft'])\n",
    "\n",
    "# Check Total Count\n",
    "print(\"Amount of listings Scraped: \"+str(len(l)))\n",
    "# List Completed if number > 0 || Empty"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "          Price Beds Baths   Square_Feet   Type  \\\n",
      "0      $739,000  3bd   4ba          1314  House   \n",
      "1      $275,000  1bd   1ba           408  House   \n",
      "2      $889,000  3bd   3ba          1757  House   \n",
      "3    $6,500,000  4bd   9ba         11517  House   \n",
      "4      $519,000  3bd   3ba          2017  House   \n",
      "..          ...  ...   ...           ...    ...   \n",
      "103    $499,000  4bd   4ba            --  House   \n",
      "104    $270,000  3bd   3ba            --  House   \n",
      "105    $225,000  4bd   3ba            --  House   \n",
      "106     $10,000    0     0  0.11acreslot   Land   \n",
      "107     $20,000    0     0   0.1acreslot   Land   \n",
      "\n",
      "                                               Address  \n",
      "0              140 Kettle Creek Rd, Cashiers, NC 28717  \n",
      "1               7 At Last Ridge Rd, Cashiers, NC 28717  \n",
      "2             760 Cashiers Lake Rd, Cashiers, NC 28717  \n",
      "3                1090 Zeb Alley Rd, Cashiers, NC 28717  \n",
      "4                92 Summerfield Ln, Cashiers, NC 28717  \n",
      "..                                                 ...  \n",
      "103  4470 Greenmeadow Lakes Cir, Winston Salem, NC ...  \n",
      "104              536 Regal Dr, Winston Salem, NC 27127  \n",
      "105          3791 Barnwell Dr, Winston Salem, NC 27105  \n",
      "106          0 Lincoln Ave #1, Winston Salem, NC 27105  \n",
      "107      2025 Harrison Ave #7, Winston Salem, NC 27105  \n",
      "\n",
      "[108 rows x 6 columns]\n"
     ]
    }
   ],
   "source": [
    "for i in range(0,len(l)):\n",
    "\n",
    "    cost.append(l[i]['pricing'])\n",
    "    beds.append(l[i]['beds'])\n",
    "    baths.append(l[i]['baths'])\n",
    "    sqft.append(l[i]['sqft'])\n",
    "    types.append(l[i]['type'])\n",
    "    address.append(l[i]['address'])\n",
    "\n",
    "\n",
    "# Create Price Column\n",
    "house_df['Price'] = cost\n",
    "\n",
    "# Create Beds Column\n",
    "house_df['Beds'] = beds\n",
    "\n",
    "# Create Baths Column\n",
    "house_df['Baths'] = baths\n",
    "\n",
    "# Create Square Feet Column\n",
    "house_df['Square_Feet'] = sqft\n",
    "\n",
    "# Create Type Column\n",
    "house_df['Type'] = types\n",
    "\n",
    "# Create Address Column\n",
    "house_df['Address'] = address\n",
    "\n",
    "\n",
    "# Format Columns as String\n",
    "house_df['Price'] = house_df['Price'].astype('str')\n",
    "house_df['Beds'] = house_df['Beds'].astype('str')\n",
    "house_df['Baths'] = house_df['Baths'].astype('str')\n",
    "house_df['Square_Feet'] = house_df['Square_Feet'].astype('str')\n",
    "house_df['Type'] = house_df['Type'].astype('str')\n",
    "house_df['Address'] = house_df['Address'].astype('str')\n",
    "\n",
    "# Print to Check Output\n",
    "print(house_df)\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Export to Excel File"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create an export to Excel File for Furthur Analysis\n",
    "\n",
    "# Create File Name\n",
    "fileName = 'RealEstateData.xlsx'\n",
    "\n",
    "# Export to Excel; Sheet Named: 'Real Estate Data';\n",
    "with pd.ExcelWriter(fileName, engine=\"openpyxl\", mode=\"a\", if_sheet_exists='overlay') as writer:\n",
    "    house_df.to_excel(writer, 'Real Estate Data', index=False, startrow=writer.sheets['Real Estate Data'].max_row)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.1"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "5238573367df39f7286bb46f9ff5f08f63a01a80960060ce41e3c79b190280fa"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
