{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Real Estate EDA - South Carolina"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Imports (Pandas - Python Data Analysis Library, Numbpy - Array Proessing Package, Seaborn - Statistical Data Visualisation, Matplotlib - Static Vizualization Library)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Standard Import Structure for EDA;\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import regex as re\n",
    "import random\n",
    "import time\n",
    "\n",
    "# Importing Requests for use in API calls.\n",
    "import requests\n",
    "\n",
    "\n",
    "# Import Standard Packages for Date and Time;\n",
    "from datetime import datetime, timedelta\n",
    "\n",
    "# Import Beautiful Soup, Selenium, for Scraping\n",
    "from bs4 import BeautifulSoup\n",
    "from selenium import webdriver\n",
    "from selenium.webdriver.common.keys import Keys\n",
    "from selenium.webdriver.common.by import By\n",
    "\n",
    "# Import packages to help with parsing Information\n",
    "import lxml\n",
    "from lxml.html.soupparser import fromstring\n",
    "import prettify\n",
    "import numbers\n",
    "import htmltext\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Random User Agent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def GET_UA():\n",
    "    uastrings = [\"Mozilla/5.0 (Windows NT 6.1; WOW64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/38.0.2125.111 Safari/537.36\",\\\n",
    "                \"Mozilla/5.0 (Windows NT 6.1; WOW64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/28.0.1500.72 Safari/537.36\",\\\n",
    "                \"Mozilla/5.0 (Macintosh; Intel Mac OS X 10_10) AppleWebKit/600.1.25 (KHTML, like Gecko) Version/8.0 Safari/600.1.25\",\\\n",
    "                \"Mozilla/5.0 (Windows NT 6.1; WOW64; rv:33.0) Gecko/20100101 Firefox/33.0\",\\\n",
    "                \"Mozilla/5.0 (Windows NT 6.3; WOW64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/38.0.2125.111 Safari/537.36\",\\\n",
    "                \"Mozilla/5.0 (Macintosh; Intel Mac OS X 10_10_0) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/38.0.2125.111 Safari/537.36\",\\\n",
    "                \"Mozilla/5.0 (Macintosh; Intel Mac OS X 10_9_5) AppleWebKit/600.1.17 (KHTML, like Gecko) Version/7.1 Safari/537.85.10\",\\\n",
    "                \"Mozilla/5.0 (Windows NT 6.1; WOW64; Trident/7.0; rv:11.0) like Gecko\",\\\n",
    "                \"Mozilla/5.0 (Windows NT 6.3; WOW64; rv:33.0) Gecko/20100101 Firefox/33.0\",\\\n",
    "                \"Mozilla/5.0 (Windows NT 6.1; WOW64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/38.0.2125.104 Safari/537.36\"\\\n",
    "                ]\n",
    " \n",
    "    return random.choice(uastrings)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Setup and Initialization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set Maximum Displayed Columns to None; All Columns Listed\n",
    "pd.options.display.max_columns = None;\n",
    "\n",
    "# Set MatPlotLib to Display Elements\n",
    "%matplotlib inline\n",
    "\n",
    "# Import Cities in CSV file for 10 most and least expenive north carolina cities.csv\n",
    "cities_df = pd.read_csv(\"scCities.csv\",header=0)\n",
    "\n",
    "#Lists for Looping through GET Requests\n",
    "urls = list()\n",
    "cities = list()\n",
    "\n",
    "# Create Headers for Future GET Requests\n",
    "req_headers = {\"User-Agent\":GET_UA(),\n",
    "    \"Accept-Language\":\"en-US,en;q=0.9\",\n",
    "    \"Accept\":\"text/html,application/xhtml+xml,application/xml;q=0.9,image/avif,image/webp,image/apng,*/*;q=0.8,application/signed-exchange;v=b3;q=0.9\",\n",
    "    \"Accept-Encoding\":\"gzip, deflate, br\",\n",
    "    \"upgrade-insecure-requests\":\"1\"}\n",
    "\n",
    "# Print cities list to double check correct information\n",
    "print(cities_df)\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Create URLs For Scraping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Checking for Sale using Zillow.com\n",
    "# Using 20 Cities we use 20 URLs\n",
    "# Using loop to collect information from csv to pass to beautiful soup\n",
    "for i in range(10):\n",
    "    for j in range(2):\n",
    "        # Get City List from cities_df\n",
    "        cities.append(str(cities_df.iat[i,j]))\n",
    "\n",
    "# SUCCESSFUL CHECKING FOR INCLUSION OF ALL OF CITIES FILES REQUIRED\n",
    "# Uncomment for initial check and recomment for readability afterwards\n",
    "# print(cities)\n",
    "\n",
    "# Remove White Space to Make A Correct URL by Replacing with '_'\n",
    "# E.g. 'Morehead City' -> 'Morehead_City'\n",
    "for i in range(0,len(cities)):\n",
    "    city = str(cities[i]).replace(' ','_')\n",
    "    cities[i] = city\n",
    "\n",
    "\n",
    "# SUCCESSFUL CHECKING FOR CORRECT FORMAT (city with space === city_with_space) REQUIRED\n",
    "# Uncomment for initial check and recomment for readability afterwards\n",
    "# print(cities)\n",
    "\n",
    "\n",
    "# Creating the URLS based upon created cities list\n",
    "for i in range(0,len(cities)):\n",
    "    urls.append('https://www.zillow.com/homes/for_sale/'+cities[i]+',-SC_rb/')\n",
    "\n",
    "# Create Additional URLS based on further page exploration...\n",
    "# Placed Last so quick excel viewing gives snapshot of individual cities and in-depth numbers are furthur down.\n",
    "# ***** Can Rarely Handle 5 Pages From 20 Cities *****\n",
    "# ***** Options Are Including More Cities and Less Pages, or Vice-Versa *****\n",
    "for i in range(2,4):\n",
    "    for j in range(0,len(cities)):\n",
    "        urls.append('https://www.zillow.com/homes/for_sale/'+cities[j]+',-SC_rb/'+str(i)+'_p/')\n",
    "\n",
    "# SUCCESSFUL CHECKING FOR APPROPRAITE URLs REQUIRED\n",
    "# Uncomment for initial check and recomment for readability afterwards\n",
    "print(str(len(urls)))\n",
    "print(urls)\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Create Session and Loop Trough URLs with GET Requests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Object for Individual Listings to be placed into List\n",
    "# List to Store Total Scraped Information\n",
    "l=[]\n",
    "obj = {}\n",
    "\n",
    "# Create a DataFrame for Storage with Columns listing Wanted Information\n",
    "house_df = pd.DataFrame(columns=['Price','Beds','Baths','Square_Feet','Type','Address'])\n",
    "\n",
    "#loop through sessions to get urls used be Reqeusts Package for pulling information\n",
    "\n",
    "with requests.Session() as s:\n",
    "\n",
    "    for i in range(0,len(urls)):\n",
    "        r = s.get(urls[i], headers=req_headers)\n",
    "    \n",
    "        # Parse bs4 response into html parser\n",
    "        soup = BeautifulSoup(r.text, 'html.parser')\n",
    "        \n",
    "        # Loop through the created soup to add to df\n",
    "        for i in soup:\n",
    "            properties = soup.find_all(\"div\",{\"class\":\"StyledPropertyCardDataWrapper-c11n-8-73-8__sc-1omp4c3-0 gXNuqr property-card-data\"})\n",
    "\n",
    "            for x in range(0,len(properties)):\n",
    "                \n",
    "                # Try and get pricing from listing excluding those without a number\n",
    "                try:\n",
    "                    obj[\"pricing\"]=properties[x].find(\"div\",{\"class\":\"StyledPropertyCardDataArea-c11n-8-73-8__sc-yipmu-0 hRqIYX\"}).text\n",
    "                except:\n",
    "                    obj[\"pricing\"]='Unknown'\n",
    "\n",
    "                # Try to get Information Sizing\n",
    "                # i.e. Beds, Baths, Square Feet, and Type (House, Apartment, Single-Family or Multi-Family Home)\n",
    "\n",
    "                try:\n",
    "                    sizeInfo=properties[x].find(\"div\",{\"class\":\"StyledPropertyCardDataArea-c11n-8-73-8__sc-yipmu-0 ghGYOB\"}).text\n",
    "\n",
    "                    # ***** Check for Studios ***** ***** Remove Them ******\n",
    "                    if 'studio' in sizeInfo:\n",
    "\n",
    "                        sizeInfo = 'Unknown Unknown Unknown Unknown'\n",
    "\n",
    "                        split = sizeInfo.split(' ',3)\n",
    "\n",
    "                        obj['beds'] = split[0]\n",
    "                        obj['baths'] = split[1]\n",
    "                        obj['sqft'] = split[2]\n",
    "                        obj['type'] = split[3]\n",
    "                    else:\n",
    "                        # Format Correctly The Sizing Information for Split\n",
    "\n",
    "                        # Steps:\n",
    "                        # Remove Sq Ft Unit\n",
    "                        # Remove Additional Info Indicator '-'\n",
    "                        # Remove 'For Sale' Descriptor\n",
    "                        # Remove WhiteSpace\n",
    "                        # Correctly Gap Beds and Baths (Bd, and Ba) to be Uniform\n",
    "                        # Remove Commas for Easier Delimitor for Later Split\n",
    "                        sizeInfo = sizeInfo.replace('sqft','',1)\n",
    "                        sizeInfo = sizeInfo.replace(' - ','')\n",
    "                        sizeInfo = sizeInfo.replace(' for sale',\"\")\n",
    "\n",
    "                        sizeInfo = sizeInfo.replace(\" \",\"\",2)\n",
    "\n",
    "                        sizeInfo = sizeInfo.replace('bds','bd')\n",
    "                        sizeInfo = sizeInfo.replace('bd','bd ')\n",
    "                        sizeInfo = sizeInfo.replace('ba','ba ')\n",
    "                        sizeInfo = sizeInfo.replace(',','')\n",
    "\n",
    "                        # Create split based on whitespace and only 3 split times for grouping construction details\n",
    "                        split = sizeInfo.split(' ',3)\n",
    "                        \n",
    "                        # Place information into object for later use\n",
    "                        # Edit Some Info --- If Land It is Ending up in 'Beds', and Type is Ending up in Baths\n",
    "\n",
    "                        if split[0].count('acre') or split[0].count('lot'):\n",
    "                            obj['sqft'] = split[0]\n",
    "                            obj['beds'] = 0\n",
    "                            obj['baths'] = 0\n",
    "                            obj['type'] = split[3]\n",
    "                        else:\n",
    "                            obj['beds'] = split[0]\n",
    "                            obj['baths'] = split[1]\n",
    "                            obj['sqft'] = split[2]\n",
    "                            obj['type'] = split[3]\n",
    "                        \n",
    "                except:\n",
    "                    obj['sqft'] = 'Unknown'\n",
    "                    obj['beds'] = 'Unknown'\n",
    "                    obj['baths'] = 'Unknown'\n",
    "                    obj['type'] = 'Unknown'\n",
    "\n",
    "                # Find Address information and exclude those without written address\n",
    "                try:\n",
    "                    obj[\"address\"]=properties[x].find(\"a\",{\"class\":\"StyledPropertyCardDataArea-c11n-8-73-8__sc-yipmu-0 lhIXlm property-card-link\"}).text\n",
    "                except:\n",
    "                    obj[\"address\"]='Unknown'\n",
    "                \n",
    "                print(obj)\n",
    "                l.append(obj)  \n",
    "                obj={}\n",
    "                time.sleep(random.randint(5,20))\n",
    "\n",
    "\n",
    "# Setup Cost to be added to data frame using list\n",
    "cost = []\n",
    "# Setup Beds to be added to data frame using list\n",
    "beds = []\n",
    "# Setup Baths to be added to data frame using list\n",
    "baths = []\n",
    "# Setup Square Feet to be added to data frame using list\n",
    "sqft = []\n",
    "# Setup Types to be added to data frame using list\n",
    "types = []\n",
    "# Setup Address to be added to data frame using list\n",
    "address = []\n",
    "\n",
    "\n",
    "# If you really want to check for log output\n",
    "\n",
    "# For Whole Log\n",
    "# print(l)\n",
    "\n",
    "\n",
    "# Check Total Count\n",
    "print(\"Amount of listings Scraped: \"+str(len(l)))\n",
    "# List Completed if number > 0 || Empty\n",
    "        \n",
    "\n",
    "\n",
    "for i in range(0,len(l)):\n",
    "\n",
    "    cost.append(l[i]['pricing'])\n",
    "    beds.append(l[i]['beds'])\n",
    "    baths.append(l[i]['baths'])\n",
    "    sqft.append(l[i]['sqft'])\n",
    "    types.append(l[i]['type'])\n",
    "    address.append(l[i]['address'])\n",
    "\n",
    "\n",
    "# Create Price Column\n",
    "house_df['Price'] = cost\n",
    "\n",
    "# Create Beds Column\n",
    "house_df['Beds'] = beds\n",
    "\n",
    "# Create Baths Column\n",
    "house_df['Baths'] = baths\n",
    "\n",
    "# Create Square Feet Column\n",
    "house_df['Square_Feet'] = sqft\n",
    "\n",
    "# Create Type Column\n",
    "house_df['Type'] = types\n",
    "\n",
    "# Create Address Column\n",
    "house_df['Address'] = address\n",
    "\n",
    "\n",
    "# Format Columns as String\n",
    "house_df['Price'] = house_df['Price'].astype('str')\n",
    "house_df['Beds'] = house_df['Beds'].astype('str')\n",
    "house_df['Baths'] = house_df['Baths'].astype('str')\n",
    "house_df['Square_Feet'] = house_df['Square_Feet'].astype('str')\n",
    "house_df['Type'] = house_df['Type'].astype('str')\n",
    "house_df['Address'] = house_df['Address'].astype('str')\n",
    "\n",
    "house_df.drop_duplicates()\n",
    "\n",
    "# Print to Check Output\n",
    "display(house_df)\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Export to Excel File"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create an export to Excel File for Furthur Analysis\n",
    "\n",
    "# Create File Name\n",
    "fileName = 'SC - RealEstateData.xlsx'\n",
    "\n",
    "# Export to Excel; Sheet Named: 'Real Estate Data';\n",
    "with pd.ExcelWriter(fileName, engine=\"openpyxl\", mode=\"w\") as writer:\n",
    "    house_df.to_excel(writer, 'SC - Real Estate Data', index=False)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.1"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "5238573367df39f7286bb46f9ff5f08f63a01a80960060ce41e3c79b190280fa"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
